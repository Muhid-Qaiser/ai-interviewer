{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install bcc==0.1.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting attrs==23.2.0 (from -r requirements.txt (line 1))Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement bcc==0.29.1 (from versions: 0.1.7, 0.1.8, 0.1.10)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for bcc==0.29.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting Babel==2.10.3 (from -r requirements.txt (line 2))\n",
      "  Using cached Babel-2.10.3-py3-none-any.whl.metadata (1.3 kB)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from transformers import pipeline\n",
    "import wave\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import sounddevice as sd\n",
    "import os\n",
    "from scipy.io.wavfile import write\n",
    "import openai\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_2396\\3889302655.py:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  PDF_FILE = \"data\\hashir-ayaz-resume.pdf\"\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "PDF_FILE = \"data\\hashir-ayaz-resume.pdf\"\n",
    "\n",
    "# Prompt to question till llm has asked 5 questions\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert AI interviewer. You have technical knowledge of whatever domain the user is interviewing for.\n",
    "Your task is to carefully review the experiences and projects provided in the context below, focusing on any technical details, challenges, or skills used.\n",
    "Based on this review, generate insightful, technically focused questions to ask the individual about their experience.\n",
    "You start by introducing the candidate to themselves and then ask a question.\n",
    "Maintaining a conversational tone is important.\n",
    "IMPORTANT POINTS:\n",
    "\n",
    "Make sure the question is related to technical skills required in the Job Position provided below.\n",
    "Focus on the Experiences and Projects section in the Context provided below.\n",
    "Frame the question in a conversational manner that is easy to understand and answer.\n",
    "After a question is answered, you should ask a follow up question to the same question if it is not answered properly or if the answer is not detailed.\n",
    "If the answer is closely related to the job position, you should probe deeper into the answer.\n",
    "\n",
    "IMPORTANT: Only follow up a question, atmost 2 times. If the user does not answer properly even after 2 times, proceed with the next question.\n",
    "Ask a total of 5 question and then conclude the conversation by saying \"Good Bye\" inorder to clarify that the interview has been concluded.\n",
    "\n",
    "\n",
    "Job Position: {field}\n",
    "Context: {context}\n",
    "\n",
    "Return the question as a single string, without introductory phrases like \"Here's a question for you.\"\n",
    "\n",
    "### Example question ### : \"Imagine you're working on a web application with a large dataset of user interactions, and you need to display this data \n",
    "dynamically in the React frontend. Describe how you would design the backend API to support efficient data retrieval and provide a responsive \n",
    "user experience. Specifically, explain how you would manage pagination, filtering, and sorting on the backend using Node.js and MongoDB.\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt to question till llm feels it is questioned enough\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert AI interviewer. You have technical knowledge of whatever domain the user is interviewing for.\n",
    "Your task is to carefully review the experiences and projects provided in the context below, focusing on any technical details, challenges, or skills used.\n",
    "Based on this review, generate insightful, technically focused questions to ask the individual about their experience.\n",
    "You start by introducing the candidate to themselves and then ask a question.\n",
    "Maintaining a conversational tone is important.\n",
    "IMPORTANT POINTS:\n",
    "\n",
    "Make sure the question is related to technical skills required in the Job Position provided below.\n",
    "Focus on the Experiences and Projects section in the Context provided below.\n",
    "Frame the question in a conversational manner that is easy to understand and answer.\n",
    "After a question is answered, you should ask a follow up question to the same question if it is not answered properly or if the answer is not detailed.\n",
    "If the answer is closely related to the job position, you should probe deeper into the answer.\n",
    "\n",
    "IMPORTANT: Only follow up a question, atmost 2 times. If the user does not answer properly even after 2 times, proceed with the next question.\n",
    "Ask questions until you feel you have questioned the candidate on a good amount of their data but make sure to not ask any more than 10 questions\n",
    "and then conclude the conversation by saying \"Good Bye\" inorder to clarify that the interview has been concluded.\n",
    "\n",
    "\n",
    "Job Position: {field}\n",
    "Context: {context}\n",
    "\n",
    "Return the question as a single string, without introductory phrases like \"Here's a question for you.\"\n",
    "\n",
    "### Example question ### : \"Imagine you're working on a web application with a large dataset of user interactions, and you need to display this data \n",
    "dynamically in the React frontend. Describe how you would design the backend API to support efficient data retrieval and provide a responsive \n",
    "user experience. Specifically, explain how you would manage pagination, filtering, and sorting on the backend using Node.js and MongoDB.\"\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Interviewer:\n",
    "    def __init__(self):\n",
    "        self.llm = None\n",
    "        self.tts = None\n",
    "        self.stt = None\n",
    "        self.memory = None\n",
    "  \n",
    "    def create_llm(self, context, field):\n",
    "\n",
    "        llm_used = ChatGroq(\n",
    "            model=\"llama3-8b-8192\",\n",
    "            temperature=0.0,\n",
    "            max_retries=2,\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate(\n",
    "            messages=[\n",
    "                # Type your Prompt\n",
    "                SystemMessagePromptTemplate.from_template(\n",
    "                    PROMPT_TEMPLATE.format(context=context, field=field)\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                HumanMessagePromptTemplate.from_template(\"\"\"{text}\"\"\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        memory = ConversationSummaryBufferMemory( llm=llm_used, max_token_limit=3000, memory_key=\"chat_history\", return_messages=True)\n",
    "        conversation = LLMChain(llm=llm_used, prompt=prompt, verbose=False, memory=memory)\n",
    "\n",
    "        return conversation\n",
    "\n",
    "    def initialize_models(self, context, field):\n",
    "\n",
    "        self.llm = self.create_llm(context, field)\n",
    "        self.tts = pipeline(\"text-to-speech\", model=\"facebook/mms-tts-eng\")\n",
    "        self.stt = pipeline(   \"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "    def read_csv(self, pdf_file):\n",
    "        return extract_text(pdf_file)\n",
    "\n",
    "    def invoke_llm(self, message):\n",
    "        # Prepare the input for the conversation\n",
    "    \n",
    "        response = self.llm.invoke(message)\n",
    "\n",
    "        question = response['text']\n",
    "        print(\"Interviewer:\")\n",
    "        print(question)\n",
    "\n",
    "        return question\n",
    "\n",
    "    def invoke_tts(self, text, save_audio=False):\n",
    "        audio = self.tts(text)\n",
    "\n",
    "        if not save_audio:\n",
    "            Audio(audio[\"audio\"], rate=16000, autoplay=True)\n",
    "        else:\n",
    "            audio_data = audio[\"audio\"]\n",
    "            audio_data = (audio_data * 32767).astype(np.int16)\n",
    "            sample_rate = 16000\n",
    "            output_file = \"audio.wav\"\n",
    "\n",
    "            with wave.open(output_file, \"wb\") as wf:\n",
    "                wf.setnchannels(1)\n",
    "                wf.setsampwidth(2)\n",
    "                wf.setframerate(sample_rate)\n",
    "                wf.writeframes(audio_data.tobytes())\n",
    "\n",
    "            print(f\"Audio saved to {output_file}\")\n",
    "\n",
    "    def invoke_stt(self, audio_file=\"audio.wav\"):\n",
    "        if not os.path.exists(audio_file) or os.path.getsize(audio_file) == 0:\n",
    "            print(\"Error: audio file does not exist or is empty.\")\n",
    "            return None\n",
    "        transcription = self.stt(audio_file)\n",
    "        return transcription[\"text\"]\n",
    "\n",
    "    def hear_user(self, duration=5, sample_rate=16000):\n",
    "        def record_audio(duration, sample_rate, device=None):\n",
    "            try:\n",
    "                print(f\"Recording for {duration} seconds...\")\n",
    "                audio = sd.rec(\n",
    "                    int(duration * sample_rate),\n",
    "                    samplerate=sample_rate,\n",
    "                    channels=1,\n",
    "                    dtype=np.float32,\n",
    "                    device=device,\n",
    "                )\n",
    "                sd.wait()\n",
    "                print(\"Recording finished!\")\n",
    "                return audio\n",
    "            except Exception as e:\n",
    "                print(\"Error recording audio:\", e)\n",
    "                return None\n",
    "\n",
    "        audio_data = record_audio(duration, sample_rate)\n",
    "        write(\"audio.wav\", sample_rate, audio_data)\n",
    "\n",
    "    def generate_report(self, interview_responses, job):\n",
    "        REPORT_TEMPLATE = \"\"\"\n",
    "        You are a recruiter and you want to hire the best candidate for the job position provided below.\n",
    "        You are being provided with a list of questions and answers from an interview. Your task is to generate a report based on the interview responses. You have expertise in the field of the job position provided below. you will give the employee a rating out of 10 and a list of strengths and weaknesses.\n",
    "        Job Position: {job}\n",
    "        Interview Responses: {interview_responses}\n",
    "        \n",
    "        The report should be in the following format:\n",
    "        {\n",
    "            strengths: [list of strengths],\n",
    "            weaknesses: [list of weaknesses],\n",
    "            overall_rating: [rating out of 10],\n",
    "            overall_feedback: [feedback],\n",
    "        }\n",
    "        \"\"\"\n",
    "        prompt_template = ChatPromptTemplate.from_template(REPORT_TEMPLATE)\n",
    "        pass\n",
    "\n",
    "    def start_interview(self, job):\n",
    "\n",
    "        # Initialize interview variables and context\n",
    "        interview_responses = []\n",
    "\n",
    "        # Loop until the interview is complete\n",
    "        while True:\n",
    "\n",
    "            # Generate question using chat history\n",
    "            current_question = self.invoke_llm(\"Hello\")\n",
    "\n",
    "            print(f\"\\nInterview Question: {current_question}\")\n",
    "\n",
    "            if \"good bye\" in current_question.lower():\n",
    "                print(\"Ending interview based on user request.\")\n",
    "                break\n",
    "\n",
    "            # Record and transcribe user's response\n",
    "            print(\"\\nRecording User's Answer:\")\n",
    "            self.hear_user(duration=20, sample_rate=16000)\n",
    "            user_response = self.invoke_stt(\"audio.wav\")\n",
    "            print(\"\\nUser Response:\", user_response)\n",
    "\n",
    "            # Append to interview responses\n",
    "            interview_responses.append(\n",
    "                {\"question\": current_question, \"answer\": user_response}\n",
    "            )\n",
    "\n",
    "            if \"stop\" in user_response.lower() :\n",
    "                print(\"Ending interview based on user request.\")\n",
    "                break\n",
    "\n",
    "\n",
    "        # Generate final report\n",
    "        interview_summary = self.generate_report(interview_responses, job)\n",
    "\n",
    "        print(\"\\nInterview Summary:\")\n",
    "        print(interview_summary)\n",
    "\n",
    "        return interview_responses, interview_summary\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interviewer = AI_Interviewer()\n",
    "cv_description = interviewer.read_csv(PDF_FILE)\n",
    "interviewer.initialize_models(cv_description, \"MERN developer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviewer.start_interview(\n",
    "    job=\"Mern stack developer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
